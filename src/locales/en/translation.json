{
  "app": {
    "title": "ZScore",
    "description": "Analyze text complexity and information content",
    "subtitle": "Shannon Entropy Calculator"
  },
  "navbar": {
    "title": "ZScore",
    "darkMode": "Dark Mode",
    "lightMode": "Light Mode",
    "language": "Language",
    "home": "Home",
    "about": "About ZScore",
    "calculator": "Calculator",
    "history": "History",
    "github": "GitHub"
  },
  "header": {
    "title": "Shannon Entropy Calculator",
    "subtitle": "Analyze text to calculate Shannon entropy, lexical diversity, word frequency, and other linguistic metrics. Enter your text below to get started."
  },
  "textInput": {
    "label": "Enter Text for Analysis",
    "placeholder": "Enter text here to analyze Shannon Entropy and other linguistic metrics...",
    "analyzeButton": "Analyze Text",
    "clearButton": "Clear",
    "examples": "Try these sample texts",
    "loadText": "Load",
    "removeText": "Remove"
  },
  "results": {
    "title": "Analysis Results",
    "wordCount": "Word Count",
    "uniqueWords": "Unique Words",
    "lexicalDiversity": "Lexical Diversity",
    "shannonEntropy": "Shannon Entropy",
    "interpretation": {
      "title": "Interpretation",
      "high": "High entropy indicates complex, unpredictable text with diverse vocabulary.",
      "medium": "Medium entropy suggests balanced, natural language with moderate complexity.",
      "low": "Low entropy indicates repetitive, predictable text with limited vocabulary."
    },
    "noResults": "No analysis results yet. Enter some text and click Analyze.",
    "ratioExplanation": "Ratio of unique words to total words",
    "entropyExplanation": "Measure of information content or unpredictability",
    "topWords": "Top 10 Word Frequencies"
  },
  "history": {
    "title": "Analysis History",
    "empty": "No analysis history yet",
    "clearButton": "Clear History",
    "timestamp": "Analyzed on",
    "loadTooltip": "Load this text",
    "removeTooltip": "Remove from history"
  },
  "footer": {
    "title": "Shannon Entropy Calculator",
    "description": "A tool for calculating information entropy and lexical diversity metrics",
    "credit": "Created with information theory principles",
    "source": "Source Code",
    "manifesto": "Read the Manifesto",
    "about": "About Shannon Entropy",
    "aboutText": "Shannon entropy quantifies the amount of information or uncertainty in a variable's possible outcomes. It was introduced by Claude Shannon in his 1948 paper \"A Mathematical Theory of Communication.\"",
    "formula": "Formula",
    "copyright": "Crafted with entropy, purpose, and a whisper of meaning. All rights reserved."
  }
} 